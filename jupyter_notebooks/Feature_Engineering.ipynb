{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* To feature engineer for future ML tasks\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* The data file, \"US_Accidents_For_Feature_Eng.csv\", which is locally saved in \"Data/Feature_Eng\"\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* The csv file, \"US_Accidents_For_ML.csv\", which is locally saved in \"Data/ML\"\n",
        "\n",
        "## Summary of Steps\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\sonia\\\\Documents\\\\VS Studio Projects\\\\US_Accidents_ML_Project\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\sonia\\\\Documents\\\\VS Studio Projects\\\\US_Accidents_ML_Project'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I load the dataset using Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Severity</th>\n",
              "      <th>Start_Time</th>\n",
              "      <th>End_Time</th>\n",
              "      <th>Start_Lat</th>\n",
              "      <th>Start_Lng</th>\n",
              "      <th>Distance(mi)</th>\n",
              "      <th>City</th>\n",
              "      <th>County</th>\n",
              "      <th>State</th>\n",
              "      <th>Timezone</th>\n",
              "      <th>Airport_Code</th>\n",
              "      <th>Temperature(F)</th>\n",
              "      <th>Wind_Chill(F)</th>\n",
              "      <th>Humidity(%)</th>\n",
              "      <th>Pressure(in)</th>\n",
              "      <th>Visibility(mi)</th>\n",
              "      <th>Wind_Direction</th>\n",
              "      <th>Wind_Speed(mph)</th>\n",
              "      <th>Precipitation(in)</th>\n",
              "      <th>Weather_Condition</th>\n",
              "      <th>Amenity</th>\n",
              "      <th>Bump</th>\n",
              "      <th>Crossing</th>\n",
              "      <th>Give_Way</th>\n",
              "      <th>Junction</th>\n",
              "      <th>No_Exit</th>\n",
              "      <th>Railway</th>\n",
              "      <th>Roundabout</th>\n",
              "      <th>Station</th>\n",
              "      <th>Stop</th>\n",
              "      <th>Traffic_Calming</th>\n",
              "      <th>Traffic_Signal</th>\n",
              "      <th>Turning_Loop</th>\n",
              "      <th>Sunrise_Sunset</th>\n",
              "      <th>Clearance_Time(hr)</th>\n",
              "      <th>Clearance_Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2022-09-08 20:54:00</td>\n",
              "      <td>2022-09-09 23:06:21</td>\n",
              "      <td>32.456486</td>\n",
              "      <td>-93.774536</td>\n",
              "      <td>0.501</td>\n",
              "      <td>Shreveport</td>\n",
              "      <td>Caddo</td>\n",
              "      <td>LA</td>\n",
              "      <td>US/Central</td>\n",
              "      <td>KSHV</td>\n",
              "      <td>78.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>29.61</td>\n",
              "      <td>10.00</td>\n",
              "      <td>CALM</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Fair</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Night</td>\n",
              "      <td>26.205833</td>\n",
              "      <td>Very Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2021-05-22 00:40:30</td>\n",
              "      <td>2021-05-25 09:56:58</td>\n",
              "      <td>36.804693</td>\n",
              "      <td>-76.189728</td>\n",
              "      <td>0.253</td>\n",
              "      <td>Virginia Beach</td>\n",
              "      <td>Virginia Beach</td>\n",
              "      <td>VA</td>\n",
              "      <td>US/Eastern</td>\n",
              "      <td>KORF</td>\n",
              "      <td>54.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>30.40</td>\n",
              "      <td>7.00</td>\n",
              "      <td>CALM</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Fair</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Night</td>\n",
              "      <td>81.274444</td>\n",
              "      <td>Very Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2022-01-21 14:25:00</td>\n",
              "      <td>2023-01-21 16:10:00</td>\n",
              "      <td>29.895741</td>\n",
              "      <td>-90.090026</td>\n",
              "      <td>1.154</td>\n",
              "      <td>Marrero</td>\n",
              "      <td>Jefferson</td>\n",
              "      <td>LA</td>\n",
              "      <td>US/Pacific</td>\n",
              "      <td>KAUD</td>\n",
              "      <td>40.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>30.28</td>\n",
              "      <td>10.00</td>\n",
              "      <td>N</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Mostly Cloudy</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Day</td>\n",
              "      <td>8761.750000</td>\n",
              "      <td>Very Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-11-27 00:44:00</td>\n",
              "      <td>2020-11-28 04:49:48</td>\n",
              "      <td>32.456459</td>\n",
              "      <td>-93.779709</td>\n",
              "      <td>0.016</td>\n",
              "      <td>Shreveport</td>\n",
              "      <td>Caddo</td>\n",
              "      <td>LA</td>\n",
              "      <td>US/Central</td>\n",
              "      <td>KSHV</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>29.80</td>\n",
              "      <td>10.00</td>\n",
              "      <td>SSE</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Cloudy</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Night</td>\n",
              "      <td>28.096667</td>\n",
              "      <td>Very Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-09-21 12:07:00</td>\n",
              "      <td>2020-09-22 15:22:36</td>\n",
              "      <td>26.966433</td>\n",
              "      <td>-82.255414</td>\n",
              "      <td>0.057</td>\n",
              "      <td>Port Charlotte</td>\n",
              "      <td>Charlotte</td>\n",
              "      <td>FL</td>\n",
              "      <td>US/Eastern</td>\n",
              "      <td>KPGD</td>\n",
              "      <td>84.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>29.99</td>\n",
              "      <td>10.00</td>\n",
              "      <td>E</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Cloudy</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Day</td>\n",
              "      <td>27.260000</td>\n",
              "      <td>Very Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>2</td>\n",
              "      <td>2021-06-10 00:18:00</td>\n",
              "      <td>2021-06-10 10:53:16</td>\n",
              "      <td>39.573795</td>\n",
              "      <td>-86.618947</td>\n",
              "      <td>4.314</td>\n",
              "      <td>Stilesville</td>\n",
              "      <td>Morgan</td>\n",
              "      <td>IN</td>\n",
              "      <td>US/Eastern</td>\n",
              "      <td>KIND</td>\n",
              "      <td>72.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>29.14</td>\n",
              "      <td>10.00</td>\n",
              "      <td>SE</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Mostly Cloudy</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Night</td>\n",
              "      <td>10.587778</td>\n",
              "      <td>Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-12-16 14:49:30</td>\n",
              "      <td>2020-12-16 22:48:00</td>\n",
              "      <td>40.001124</td>\n",
              "      <td>-75.342886</td>\n",
              "      <td>0.634</td>\n",
              "      <td>Bryn Mawr</td>\n",
              "      <td>Delaware</td>\n",
              "      <td>PA</td>\n",
              "      <td>US/Eastern</td>\n",
              "      <td>KLOM</td>\n",
              "      <td>26.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>29.81</td>\n",
              "      <td>0.75</td>\n",
              "      <td>ENE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Snow</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Day</td>\n",
              "      <td>7.975000</td>\n",
              "      <td>Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>2</td>\n",
              "      <td>2022-12-26 14:44:37</td>\n",
              "      <td>2022-12-27 00:16:30</td>\n",
              "      <td>34.988932</td>\n",
              "      <td>-85.493085</td>\n",
              "      <td>1.560</td>\n",
              "      <td>Guild</td>\n",
              "      <td>Marion</td>\n",
              "      <td>TN</td>\n",
              "      <td>US/Eastern</td>\n",
              "      <td>KCHA</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>29.51</td>\n",
              "      <td>10.00</td>\n",
              "      <td>SSW</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Cloudy</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Day</td>\n",
              "      <td>9.531389</td>\n",
              "      <td>Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-11-14 18:44:30</td>\n",
              "      <td>2020-11-15 03:54:02</td>\n",
              "      <td>40.773530</td>\n",
              "      <td>-74.034951</td>\n",
              "      <td>0.686</td>\n",
              "      <td>Union City</td>\n",
              "      <td>Hudson</td>\n",
              "      <td>NJ</td>\n",
              "      <td>US/Eastern</td>\n",
              "      <td>KNYC</td>\n",
              "      <td>49.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>30.13</td>\n",
              "      <td>10.00</td>\n",
              "      <td>CALM</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Fair</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Night</td>\n",
              "      <td>9.158889</td>\n",
              "      <td>Long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>3</td>\n",
              "      <td>2021-07-09 08:14:21</td>\n",
              "      <td>2021-07-09 17:15:16</td>\n",
              "      <td>40.739929</td>\n",
              "      <td>-73.846359</td>\n",
              "      <td>0.450</td>\n",
              "      <td>Corona</td>\n",
              "      <td>Queens</td>\n",
              "      <td>NY</td>\n",
              "      <td>US/Eastern</td>\n",
              "      <td>KLGA</td>\n",
              "      <td>73.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>29.66</td>\n",
              "      <td>4.00</td>\n",
              "      <td>N</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>Rain</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Day</td>\n",
              "      <td>9.015278</td>\n",
              "      <td>Long</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Severity           Start_Time             End_Time  Start_Lat  \\\n",
              "0            2  2022-09-08 20:54:00  2022-09-09 23:06:21  32.456486   \n",
              "1            2  2021-05-22 00:40:30  2021-05-25 09:56:58  36.804693   \n",
              "2            2  2022-01-21 14:25:00  2023-01-21 16:10:00  29.895741   \n",
              "3            2  2020-11-27 00:44:00  2020-11-28 04:49:48  32.456459   \n",
              "4            2  2020-09-21 12:07:00  2020-09-22 15:22:36  26.966433   \n",
              "...        ...                  ...                  ...        ...   \n",
              "9995         2  2021-06-10 00:18:00  2021-06-10 10:53:16  39.573795   \n",
              "9996         2  2020-12-16 14:49:30  2020-12-16 22:48:00  40.001124   \n",
              "9997         2  2022-12-26 14:44:37  2022-12-27 00:16:30  34.988932   \n",
              "9998         2  2020-11-14 18:44:30  2020-11-15 03:54:02  40.773530   \n",
              "9999         3  2021-07-09 08:14:21  2021-07-09 17:15:16  40.739929   \n",
              "\n",
              "      Start_Lng  Distance(mi)            City          County State  \\\n",
              "0    -93.774536         0.501      Shreveport           Caddo    LA   \n",
              "1    -76.189728         0.253  Virginia Beach  Virginia Beach    VA   \n",
              "2    -90.090026         1.154         Marrero       Jefferson    LA   \n",
              "3    -93.779709         0.016      Shreveport           Caddo    LA   \n",
              "4    -82.255414         0.057  Port Charlotte       Charlotte    FL   \n",
              "...         ...           ...             ...             ...   ...   \n",
              "9995 -86.618947         4.314     Stilesville          Morgan    IN   \n",
              "9996 -75.342886         0.634       Bryn Mawr        Delaware    PA   \n",
              "9997 -85.493085         1.560           Guild          Marion    TN   \n",
              "9998 -74.034951         0.686      Union City          Hudson    NJ   \n",
              "9999 -73.846359         0.450          Corona          Queens    NY   \n",
              "\n",
              "        Timezone Airport_Code  Temperature(F)  Wind_Chill(F)  Humidity(%)  \\\n",
              "0     US/Central         KSHV            78.0           78.0         62.0   \n",
              "1     US/Eastern         KORF            54.0           54.0         90.0   \n",
              "2     US/Pacific         KAUD            40.0           33.0         58.0   \n",
              "3     US/Central         KSHV            62.0           62.0         75.0   \n",
              "4     US/Eastern         KPGD            84.0           84.0         69.0   \n",
              "...          ...          ...             ...            ...          ...   \n",
              "9995  US/Eastern         KIND            72.0           72.0         91.0   \n",
              "9996  US/Eastern         KLOM            26.0           15.0         92.0   \n",
              "9997  US/Eastern         KCHA            33.0           33.0         35.0   \n",
              "9998  US/Eastern         KNYC            49.0           49.0         41.0   \n",
              "9999  US/Eastern         KLGA            73.0           73.0         87.0   \n",
              "\n",
              "      Pressure(in)  Visibility(mi) Wind_Direction  Wind_Speed(mph)  \\\n",
              "0            29.61           10.00           CALM              0.0   \n",
              "1            30.40            7.00           CALM              0.0   \n",
              "2            30.28           10.00              N             10.0   \n",
              "3            29.80           10.00            SSE              8.0   \n",
              "4            29.99           10.00              E             18.0   \n",
              "...            ...             ...            ...              ...   \n",
              "9995         29.14           10.00             SE              5.0   \n",
              "9996         29.81            0.75            ENE             13.0   \n",
              "9997         29.51           10.00            SSW              3.0   \n",
              "9998         30.13           10.00           CALM              0.0   \n",
              "9999         29.66            4.00              N             13.0   \n",
              "\n",
              "      Precipitation(in) Weather_Condition  Amenity   Bump  Crossing  Give_Way  \\\n",
              "0                  0.00              Fair    False  False     False     False   \n",
              "1                  0.00              Fair    False  False      True     False   \n",
              "2                  0.00     Mostly Cloudy    False  False     False     False   \n",
              "3                  0.00            Cloudy    False  False     False     False   \n",
              "4                  0.00            Cloudy    False  False     False     False   \n",
              "...                 ...               ...      ...    ...       ...       ...   \n",
              "9995               0.00     Mostly Cloudy    False  False     False     False   \n",
              "9996               0.00              Snow    False  False     False     False   \n",
              "9997               0.00            Cloudy    False  False     False     False   \n",
              "9998               0.00              Fair    False  False      True     False   \n",
              "9999               0.06              Rain    False  False     False     False   \n",
              "\n",
              "      Junction  No_Exit  Railway  Roundabout  Station   Stop  Traffic_Calming  \\\n",
              "0        False    False    False       False    False  False            False   \n",
              "1        False    False    False       False    False  False            False   \n",
              "2         True    False    False       False    False  False            False   \n",
              "3        False    False    False       False    False  False            False   \n",
              "4        False    False    False       False    False  False            False   \n",
              "...        ...      ...      ...         ...      ...    ...              ...   \n",
              "9995     False    False    False       False    False  False            False   \n",
              "9996     False    False    False       False    False  False            False   \n",
              "9997     False    False    False       False    False  False            False   \n",
              "9998     False    False    False       False     True   True            False   \n",
              "9999     False    False    False       False    False  False            False   \n",
              "\n",
              "      Traffic_Signal  Turning_Loop Sunrise_Sunset  Clearance_Time(hr)  \\\n",
              "0              False         False          Night           26.205833   \n",
              "1               True         False          Night           81.274444   \n",
              "2              False         False            Day         8761.750000   \n",
              "3              False         False          Night           28.096667   \n",
              "4              False         False            Day           27.260000   \n",
              "...              ...           ...            ...                 ...   \n",
              "9995           False         False          Night           10.587778   \n",
              "9996           False         False            Day            7.975000   \n",
              "9997           False         False            Day            9.531389   \n",
              "9998            True         False          Night            9.158889   \n",
              "9999           False         False            Day            9.015278   \n",
              "\n",
              "     Clearance_Class  \n",
              "0          Very Long  \n",
              "1          Very Long  \n",
              "2          Very Long  \n",
              "3          Very Long  \n",
              "4          Very Long  \n",
              "...              ...  \n",
              "9995            Long  \n",
              "9996            Long  \n",
              "9997            Long  \n",
              "9998            Long  \n",
              "9999            Long  \n",
              "\n",
              "[10000 rows x 36 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"Data/Feature_Eng/US_Accidents_For_Feature_Eng.csv\")\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detailed Look at Categorical Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, I'm going to have a detailed look at the categorical variables and decide which ones to modify, drop or carry forward. For numerical variables, I will similarly decide which variables to modify, drop or carry forward after EDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start_Time: 9791\n",
            "End_Time: 9920\n",
            "City: 2433\n",
            "County: 754\n",
            "State: 48\n",
            "Timezone: 4\n",
            "Airport_Code: 993\n",
            "Wind_Direction: 23\n",
            "Weather_Condition: 51\n",
            "Sunrise_Sunset: 2\n",
            "Clearance_Class: 4\n"
          ]
        }
      ],
      "source": [
        "for col in df.select_dtypes(include=\"object\").columns:\n",
        "    print(f\"{col}: {df[col].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, I would like to strip \"US/\" from each value under \"Timezone\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['US/Central', 'US/Eastern', 'US/Pacific', 'US/Mountain'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Timezone\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Timezone\n",
              "Eastern     4298\n",
              "Pacific     2521\n",
              "Central     2447\n",
              "Mountain     734\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Timezone\"] = df[\"Timezone\"].str.replace(\"US/\", \"\", regex=False)\n",
        "df[\"Timezone\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, I will take a look at the values in \"Sunrise_Sunset\" and ensure they are valid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sunrise_Sunset\n",
              "Day      6445\n",
              "Night    3555\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Sunrise_Sunset\"]. value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, I will take a look at values for \"Wind_Direction\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Wind_Direction\n",
              "CALM        1770\n",
              "S            799\n",
              "N            628\n",
              "E            595\n",
              "W            574\n",
              "SSE          515\n",
              "NW           478\n",
              "VAR          473\n",
              "WNW          453\n",
              "SW           448\n",
              "SSW          448\n",
              "NNW          429\n",
              "WSW          427\n",
              "SE           424\n",
              "ENE          419\n",
              "NNE          363\n",
              "ESE          362\n",
              "NE           359\n",
              "North         14\n",
              "East           6\n",
              "Variable       6\n",
              "South          5\n",
              "West           5\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Wind_Direction\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I can see that we have values which are the same but recorded differently as shorthand or longhand, for example, \"S\" and \"South\". I will create a map to convert the longhand to shorthand version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['CALM', 'N', 'SSE', 'E', 'S', 'WNW', 'NNW', 'SE', 'ENE', 'NW',\n",
              "       'NE', 'WSW', 'NNE', 'SW', 'W', 'ESE', 'VAR', 'SSW'], dtype=object)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define mapping\n",
        "direction_map = {\n",
        "    \"Variable\": \"VAR\",\n",
        "    \"South\": \"S\",\n",
        "    \"North\": \"N\",\n",
        "    \"West\": \"W\",\n",
        "    \"East\": \"E\"\n",
        "}\n",
        "\n",
        "# apply mapping\n",
        "df[\"Wind_Direction\"] = df[\"Wind_Direction\"].replace(direction_map)\n",
        "\n",
        "# check unique values again\n",
        "df[\"Wind_Direction\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, I will look at values for \"Weather_Condition\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Weather_Condition\n",
              "Fair                       4718\n",
              "Cloudy                     1598\n",
              "Mostly Cloudy              1308\n",
              "Partly Cloudy               808\n",
              "Light Rain                  453\n",
              "Light Snow                  199\n",
              "Fog                         160\n",
              "Rain                        119\n",
              "Haze                         83\n",
              "Fair / Windy                 65\n",
              "Cloudy / Windy               45\n",
              "Heavy Rain                   41\n",
              "Mostly Cloudy / Windy        37\n",
              "Snow                         32\n",
              "Thunder in the Vicinity      32\n",
              "Smoke                        29\n",
              "Overcast                     28\n",
              "Light Drizzle                27\n",
              "Thunder                      24\n",
              "Wintry Mix                   24\n",
              "T-Storm                      18\n",
              "Light Rain / Windy           17\n",
              "Partly Cloudy / Windy        16\n",
              "Light Rain with Thunder      14\n",
              "Light Snow / Windy           13\n",
              "Heavy T-Storm                11\n",
              "Heavy Snow                    9\n",
              "Shallow Fog                   6\n",
              "Light Freezing Rain           5\n",
              "T-Storm / Windy               5\n",
              "Mist                          5\n",
              "Light Drizzle / Windy         4\n",
              "Heavy Rain / Windy            4\n",
              "Drizzle                       4\n",
              "Snow / Windy                  4\n",
              "Patches of Fog                4\n",
              "Haze / Windy                  4\n",
              "Rain / Windy                  3\n",
              "Smoke / Windy                 3\n",
              "Showers in the Vicinity       3\n",
              "Blowing Snow / Windy          3\n",
              "Heavy T-Storm / Windy         3\n",
              "Heavy Drizzle                 2\n",
              "Drizzle and Fog               2\n",
              "Fog / Windy                   2\n",
              "Drifting Snow / Windy         1\n",
              "Light Freezing Drizzle        1\n",
              "Clear                         1\n",
              "Light Snow Shower             1\n",
              "Heavy Snow / Windy            1\n",
              "Ice Pellets                   1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Weather_Condition\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I am going to create a new column, \"Weather_Simplified\" to reduce and simplify the number of different types of weather conditions. I will create a csv file that maps each \"Weather_Condition\" to \"Weather_Simplified\" and then merge \"Weather_Simplified\" as a new column in DataFrame.  \n",
        "\n",
        "\"Weather_Simplified\" will be constructed such that all types of rain or snow or fog etc. are grouped together. Mixed weather conditions were consistently found to be \"Condition\"/ \"Windy\". In this case, all simplified to \"Condition\" with \"Windy\" dropped, unless the condition was \"Fair\", \"Cloudy\" or \"Mostly Cloudy\", then it simplified to \"Windy\". This was to record the 'worst' of the mixed conditions, which is a subjective point of view and should be reviewed with the client. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied to clipboard! You can now paste into Excel.\n"
          ]
        }
      ],
      "source": [
        "# Get unique simplified weather conditions\n",
        "unique_conditions = df['Weather_Condition'].dropna().unique()\n",
        "\n",
        "# Convert to a DataFrame for better Excel paste\n",
        "unique_df = pd.DataFrame(unique_conditions, columns=['Weather_Condition'])\n",
        "\n",
        "# Copy to clipboard\n",
        "unique_df.to_clipboard(index=False)  # No index column\n",
        "print(\"Copied to clipboard! You can now paste into Excel.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weather_Condition</th>\n",
              "      <th>Weather_Simplified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fair</td>\n",
              "      <td>Fair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mostly Cloudy</td>\n",
              "      <td>Cloudy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cloudy</td>\n",
              "      <td>Cloudy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Partly Cloudy</td>\n",
              "      <td>Rain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Light Rain</td>\n",
              "      <td>Rain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Weather_Condition Weather_Simplified\n",
              "0              Fair               Fair\n",
              "1     Mostly Cloudy             Cloudy\n",
              "2            Cloudy             Cloudy\n",
              "3     Partly Cloudy               Rain\n",
              "4        Light Rain               Rain"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weather_map = pd.read_csv(\"Data/Raw/Supporting_files/Weather_Condition_Map.csv\")\n",
        "weather_map.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Weather_Condition values successfully mapped.\n"
          ]
        }
      ],
      "source": [
        "df = df.merge(weather_map, on=\"Weather_Condition\", how=\"left\")\n",
        "\n",
        "# check if any Weather_Condition values didn't get mapped\n",
        "unmapped = df[df[\"Weather_Simplified\"].isna()][\"Weather_Condition\"].unique()\n",
        "\n",
        "if len(unmapped) > 0:\n",
        "    print(\"Warning: The following Weather_Condition values were not mapped:\")\n",
        "    print(unmapped)\n",
        "else:\n",
        "    print(\"All Weather_Condition values successfully mapped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Weather_Simplified\n",
              "Fair      4719\n",
              "Cloudy    2934\n",
              "Rain      1485\n",
              "Snow       263\n",
              "Fog        174\n",
              "Windy      163\n",
              "Storm      107\n",
              "Haze        87\n",
              "Smoke       32\n",
              "Wintry      24\n",
              "Ice          7\n",
              "Mist         5\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Weather_Simplified\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, I will look at the values for \"State\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State\n",
              "CA    1820\n",
              "FL    1493\n",
              "LA     739\n",
              "TX     562\n",
              "OR     477\n",
              "NY     421\n",
              "SC     375\n",
              "PA     353\n",
              "NC     349\n",
              "AZ     316\n",
              "VA     313\n",
              "OK     273\n",
              "TN     188\n",
              "MN     184\n",
              "IL     154\n",
              "NJ     151\n",
              "WA     150\n",
              "GA     143\n",
              "MT     141\n",
              "MI     136\n",
              "MD     135\n",
              "AL     123\n",
              "CO     107\n",
              "OH     106\n",
              "UT      89\n",
              "CT      83\n",
              "MO      64\n",
              "MA      60\n",
              "WV      50\n",
              "IN      47\n",
              "KS      46\n",
              "NV      38\n",
              "DE      36\n",
              "DC      33\n",
              "IA      30\n",
              "NE      30\n",
              "WI      28\n",
              "AR      27\n",
              "ID      26\n",
              "WY      25\n",
              "KY      24\n",
              "MS      20\n",
              "NM      16\n",
              "RI      11\n",
              "NH       3\n",
              "ME       2\n",
              "ND       2\n",
              "VT       1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"State\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I am going to create a new column, \"State_Other\", where States that appear less than 5 times are grouped as \"Other\", otherwise the State appears as it is in \"State\". "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['LA', 'VA', 'FL', 'OK', 'PA', 'KY', 'OR', 'AZ', 'MT', 'NJ', 'NE',\n",
              "       'NY', 'NC', 'CA', 'KS', 'WY', 'TN', 'SC', 'MN', 'GA', 'MS', 'CO',\n",
              "       'ID', 'WA', 'DE', 'UT', 'TX', 'OH', 'MO', 'NM', 'MI', 'IA', 'IL',\n",
              "       'DC', 'NV', 'IN', 'WV', 'AL', 'CT', 'WI', 'MD', 'AR', 'ME', 'MA',\n",
              "       'RI', 'NH', 'VT', 'ND'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts = df[\"State\"].value_counts()\n",
        "\n",
        "df[\"State_Other\"] = df[\"State\"].apply(lambda x: x if counts[x] > 5 else \"Other\")\n",
        "\n",
        "df[\"State_Other\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, I will look at how many unique values there are for \"City\" and how many appear only once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2433"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"City\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of cities that appear only once: 1266\n"
          ]
        }
      ],
      "source": [
        "# Count occurrences of each city\n",
        "city_counts = df['City'].value_counts()\n",
        "\n",
        "# Count how many cities appear exactly once\n",
        "low_cities_count = (city_counts < 2).sum()\n",
        "\n",
        "print(f\"Number of cities that appear only once: {low_cities_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I believe there are too many cities that appear only once to either leave them in or group as \"Other\". Instead, I will use \"City\" to extract population counts and then ultimately drop this variable.\n",
        "\n",
        "I have found both city and county population data which I have downloaded from the United States Census Bureau. I will first attempt to map \"Population\" using \"City\", and for those not found, using \"County\".\n",
        "\n",
        "I will read in the csv file for city populations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abbeville city, Alabama</td>\n",
              "      <td>2,349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adamsville city, Alabama</td>\n",
              "      <td>4,393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Addison town, Alabama</td>\n",
              "      <td>661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Akron town, Alabama</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alabaster city, Alabama</td>\n",
              "      <td>33,342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21408</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21409</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21410</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21411</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21412</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21413 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Area Population\n",
              "0       Abbeville city, Alabama      2,349\n",
              "1      Adamsville city, Alabama      4,393\n",
              "2         Addison town, Alabama        661\n",
              "3           Akron town, Alabama        229\n",
              "4       Alabaster city, Alabama     33,342\n",
              "...                         ...        ...\n",
              "21408                       NaN        NaN\n",
              "21409                       NaN        NaN\n",
              "21410                       NaN        NaN\n",
              "21411                       NaN        NaN\n",
              "21412                       NaN        NaN\n",
              "\n",
              "[21413 rows x 2 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_city_pop = pd.read_csv(\"Data/Raw//Supporting_files/City_Pop_Map.csv\", encoding='latin1')\n",
        "df_city_pop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I will drop rows which have only \"NaN\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abbeville city, Alabama</td>\n",
              "      <td>2,349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adamsville city, Alabama</td>\n",
              "      <td>4,393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Addison town, Alabama</td>\n",
              "      <td>661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Akron town, Alabama</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alabaster city, Alabama</td>\n",
              "      <td>33,342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19474</th>\n",
              "      <td>Wamsutter town, Wyoming</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19475</th>\n",
              "      <td>Wheatland town, Wyoming</td>\n",
              "      <td>3,586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19476</th>\n",
              "      <td>Worland city, Wyoming</td>\n",
              "      <td>4,784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19477</th>\n",
              "      <td>Wright town, Wyoming</td>\n",
              "      <td>1,645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19478</th>\n",
              "      <td>Yoder town, Wyoming</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19479 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Area Population\n",
              "0       Abbeville city, Alabama      2,349\n",
              "1      Adamsville city, Alabama      4,393\n",
              "2         Addison town, Alabama        661\n",
              "3           Akron town, Alabama        229\n",
              "4       Alabaster city, Alabama     33,342\n",
              "...                         ...        ...\n",
              "19474   Wamsutter town, Wyoming        203\n",
              "19475   Wheatland town, Wyoming      3,586\n",
              "19476     Worland city, Wyoming      4,784\n",
              "19477      Wright town, Wyoming      1,645\n",
              "19478       Yoder town, Wyoming        129\n",
              "\n",
              "[19479 rows x 2 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_city_pop = df_city_pop.dropna(how='all')\n",
        "df_city_pop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I can see that city/ towns are together with their states, separated by a comma under the heading \"Area\". I will create a new column \"City\" for city/ towns, and a new column \"State\" for the states. I will also strip the word \"city\" from the names because they aren't recorded as \"... city\" in the US_Accidents dataset. Lastly, I will drop the column \"Area\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Population</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2,349</td>\n",
              "      <td>Abbeville</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4,393</td>\n",
              "      <td>Adamsville</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>661</td>\n",
              "      <td>Addison town</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>229</td>\n",
              "      <td>Akron town</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33,342</td>\n",
              "      <td>Alabaster</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Population          City    State\n",
              "0      2,349     Abbeville  Alabama\n",
              "1      4,393    Adamsville  Alabama\n",
              "2        661  Addison town  Alabama\n",
              "3        229    Akron town  Alabama\n",
              "4     33,342     Alabaster  Alabama"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_city_pop = df_city_pop.copy()\n",
        "\n",
        "# Remove leading/trailing spaces \n",
        "df_city_pop['Area'] = df_city_pop['Area'].str.strip()\n",
        "\n",
        "# Split at the last comma into city and state\n",
        "df_city_pop[['City', 'State']] = df_city_pop['Area'].str.rsplit(',', n=1, expand=True)\n",
        "\n",
        "# Strip extra spaces and remove \"city\" in the name\n",
        "df_city_pop['City'] = df_city_pop['City'].str.replace(r'\\b[Cc]ity\\b', '', regex=True).str.strip()\n",
        "df_city_pop['State'] = df_city_pop['State'].str.strip()\n",
        "\n",
        "# Optional: drop 'Area'\n",
        "df_city_pop = df_city_pop.drop(columns=['Area'])\n",
        "\n",
        "df_city_pop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, I will create a new column \"State_Abbrev\" and map state abbreviations which match those found in the US_Accidents dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Population</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>State_Abbrev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2,349</td>\n",
              "      <td>Abbeville</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4,393</td>\n",
              "      <td>Adamsville</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>661</td>\n",
              "      <td>Addison town</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>229</td>\n",
              "      <td>Akron town</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33,342</td>\n",
              "      <td>Alabaster</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Population          City    State State_Abbrev\n",
              "0      2,349     Abbeville  Alabama           AL\n",
              "1      4,393    Adamsville  Alabama           AL\n",
              "2        661  Addison town  Alabama           AL\n",
              "3        229    Akron town  Alabama           AL\n",
              "4     33,342     Alabaster  Alabama           AL"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dictionary of US states\n",
        "state_map = {\n",
        "    'Alabama':'AL', 'Alaska':'AK', 'Arizona':'AZ', 'Arkansas':'AR', 'California':'CA',\n",
        "    'Colorado':'CO', 'Connecticut':'CT', 'Delaware':'DE', 'District of Columbia':'DC',\n",
        "    'Florida':'FL', 'Georgia':'GA', 'Hawaii':'HI', 'Idaho':'ID', 'Illinois':'IL',\n",
        "    'Indiana':'IN', 'Iowa':'IA', 'Kansas':'KS', 'Kentucky':'KY', 'Louisiana':'LA',\n",
        "    'Maine':'ME', 'Maryland':'MD', 'Massachusetts':'MA', 'Michigan':'MI', 'Minnesota':'MN',\n",
        "    'Mississippi':'MS', 'Missouri':'MO', 'Montana':'MT', 'Nebraska':'NE', 'Nevada':'NV',\n",
        "    'New Hampshire':'NH', 'New Jersey':'NJ', 'New Mexico':'NM', 'New York':'NY',\n",
        "    'North Carolina':'NC', 'North Dakota':'ND', 'Ohio':'OH', 'Oklahoma':'OK', 'Oregon':'OR',\n",
        "    'Pennsylvania':'PA', 'Rhode Island':'RI', 'South Carolina':'SC', 'South Dakota':'SD',\n",
        "    'Tennessee':'TN', 'Texas':'TX', 'Utah':'UT', 'Vermont':'VT', 'Virginia':'VA',\n",
        "    'Washington':'WA', 'West Virginia':'WV', 'Wisconsin':'WI', 'Wyoming':'WY'\n",
        "}\n",
        "\n",
        "# Apply mapping\n",
        "df_city_pop['State_Abbrev'] = df_city_pop['State'].map(state_map)\n",
        "df_city_pop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, I will drop the \"State\" column so I can rename \"State_Abbrev\" to \"State\". This will allow me to match on both \"City\" and \"State\" when I merge DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Population</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2,349</td>\n",
              "      <td>Abbeville</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4,393</td>\n",
              "      <td>Adamsville</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>661</td>\n",
              "      <td>Addison town</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>229</td>\n",
              "      <td>Akron town</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33,342</td>\n",
              "      <td>Alabaster</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Population          City State\n",
              "0      2,349     Abbeville    AL\n",
              "1      4,393    Adamsville    AL\n",
              "2        661  Addison town    AL\n",
              "3        229    Akron town    AL\n",
              "4     33,342     Alabaster    AL"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop the original full state name column\n",
        "df_city_pop = df_city_pop.drop(columns=['State'])\n",
        "\n",
        "# Rename the abbreviation column\n",
        "df_city_pop = df_city_pop.rename(columns={'State_Abbrev': 'State'})\n",
        "df_city_pop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, I will create a \"City_norm\" and \"State_norm\" column in each DataFrame to increase the chances of finding a match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_city(name):\n",
        "    name = name.lower().strip()\n",
        "    \n",
        "    # Remove parenthetical content, e.g., \" (city)\"\n",
        "    name = re.sub(r\"\\s*\\(.*?\\)\\s*\", \"\", name)\n",
        "    \n",
        "    # Remove common suffixes\n",
        "    remove_terms = [\" city\"]\n",
        "    for term in remove_terms:\n",
        "        name = name.replace(term, \"\")\n",
        "    \n",
        "    # Remove extra spaces\n",
        "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
        "    \n",
        "    return name\n",
        "\n",
        "# Apply to both datasets\n",
        "df['City_norm'] = df['City'].apply(normalize_city)\n",
        "df['State_norm'] = df['State'].str.lower().str.strip()\n",
        "\n",
        "df_city_pop['City_norm'] = df_city_pop['City'].apply(normalize_city)\n",
        "df_city_pop['State_norm'] = df_city_pop['State'].str.lower().str.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before mergining, I will take a look at how many cities have been matched compared with how many are not matched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cities in df_balanced found in df_pop: 1383\n",
            "Cities in df_balanced NOT found in df_pop: 1353\n"
          ]
        }
      ],
      "source": [
        "# Make sets of cities (and states) in each dataset\n",
        "acc_cities = set(zip(df['City_norm'], df['State_norm']))\n",
        "pop_cities = set(zip(df_city_pop['City_norm'], df_city_pop['State_norm']))\n",
        "\n",
        "# Count how many cities in df_balanced are in df_pop\n",
        "matched = acc_cities & pop_cities\n",
        "print(f\"Cities in df_balanced found in df_pop: {len(matched)}\")\n",
        "print(f\"Cities in df_balanced NOT found in df_pop: {len(acc_cities - pop_cities)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, I will read in the csv file containing county populations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>County</th>\n",
              "      <th>Population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.Autauga County, Alabama</td>\n",
              "      <td>58,800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>.Baldwin County, Alabama</td>\n",
              "      <td>231,767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>.Barbour County, Alabama</td>\n",
              "      <td>25,226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>.Bibb County, Alabama</td>\n",
              "      <td>22,284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>.Blount County, Alabama</td>\n",
              "      <td>59,130</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     County Population\n",
              "0  .Autauga County, Alabama     58,800\n",
              "1  .Baldwin County, Alabama    231,767\n",
              "2  .Barbour County, Alabama     25,226\n",
              "3     .Bibb County, Alabama     22,284\n",
              "4   .Blount County, Alabama     59,130"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_county_pop = pd.read_csv(\"Data/Raw/Supporting_files/County_Pop_Map.csv\", encoding='latin1')\n",
        "df_county_pop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once, again, I need to formate and split \"County\" into \"County\" and \"State\" columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>County</th>\n",
              "      <th>Population</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Autauga</td>\n",
              "      <td>58,800</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baldwin</td>\n",
              "      <td>231,767</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Barbour</td>\n",
              "      <td>25,226</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bibb</td>\n",
              "      <td>22,284</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Blount</td>\n",
              "      <td>59,130</td>\n",
              "      <td>Alabama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    County Population    State\n",
              "0  Autauga     58,800  Alabama\n",
              "1  Baldwin    231,767  Alabama\n",
              "2  Barbour     25,226  Alabama\n",
              "3     Bibb     22,284  Alabama\n",
              "4   Blount     59,130  Alabama"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_county_pop = df_county_pop.copy()\n",
        "\n",
        "# Step 1: Remove leading \".\"\n",
        "df_county_pop[\"County\"] = df_county_pop[\"County\"].str.lstrip(\".\")\n",
        "\n",
        "# Step 2: Split into \"County\" and \"State\"\n",
        "df_county_pop[[\"County\", \"State\"]] = df_county_pop[\"County\"].str.replace(\" County\", \"\", regex=False).str.rsplit(\",\", n=1, expand=True)\n",
        "\n",
        "# Step 3: Clean up whitespace\n",
        "df_county_pop[\"County\"] = df_county_pop[\"County\"].str.strip()\n",
        "df_county_pop[\"State\"] = df_county_pop[\"State\"].str.strip()\n",
        "\n",
        "# Check result\n",
        "df_county_pop.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create \"County_Abbrev\" column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>County</th>\n",
              "      <th>Population</th>\n",
              "      <th>State</th>\n",
              "      <th>State_Abbrev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Autauga</td>\n",
              "      <td>58,800</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baldwin</td>\n",
              "      <td>231,767</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Barbour</td>\n",
              "      <td>25,226</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bibb</td>\n",
              "      <td>22,284</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Blount</td>\n",
              "      <td>59,130</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    County Population    State State_Abbrev\n",
              "0  Autauga     58,800  Alabama           AL\n",
              "1  Baldwin    231,767  Alabama           AL\n",
              "2  Barbour     25,226  Alabama           AL\n",
              "3     Bibb     22,284  Alabama           AL\n",
              "4   Blount     59,130  Alabama           AL"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dictionary of US states\n",
        "state_map = {\n",
        "    'Alabama':'AL', 'Alaska':'AK', 'Arizona':'AZ', 'Arkansas':'AR', 'California':'CA',\n",
        "    'Colorado':'CO', 'Connecticut':'CT', 'Delaware':'DE', 'District of Columbia':'DC',\n",
        "    'Florida':'FL', 'Georgia':'GA', 'Hawaii':'HI', 'Idaho':'ID', 'Illinois':'IL',\n",
        "    'Indiana':'IN', 'Iowa':'IA', 'Kansas':'KS', 'Kentucky':'KY', 'Louisiana':'LA',\n",
        "    'Maine':'ME', 'Maryland':'MD', 'Massachusetts':'MA', 'Michigan':'MI', 'Minnesota':'MN',\n",
        "    'Mississippi':'MS', 'Missouri':'MO', 'Montana':'MT', 'Nebraska':'NE', 'Nevada':'NV',\n",
        "    'New Hampshire':'NH', 'New Jersey':'NJ', 'New Mexico':'NM', 'New York':'NY',\n",
        "    'North Carolina':'NC', 'North Dakota':'ND', 'Ohio':'OH', 'Oklahoma':'OK', 'Oregon':'OR',\n",
        "    'Pennsylvania':'PA', 'Rhode Island':'RI', 'South Carolina':'SC', 'South Dakota':'SD',\n",
        "    'Tennessee':'TN', 'Texas':'TX', 'Utah':'UT', 'Vermont':'VT', 'Virginia':'VA',\n",
        "    'Washington':'WA', 'West Virginia':'WV', 'Wisconsin':'WI', 'Wyoming':'WY'\n",
        "}\n",
        "\n",
        "# Apply mapping\n",
        "df_county_pop['State_Abbrev'] = df_county_pop['State'].map(state_map)\n",
        "df_county_pop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then drop \"State\" so I can rename \"State_Abbrev\" as \"State\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>County</th>\n",
              "      <th>Population</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Autauga</td>\n",
              "      <td>58,800</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baldwin</td>\n",
              "      <td>231,767</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Barbour</td>\n",
              "      <td>25,226</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bibb</td>\n",
              "      <td>22,284</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Blount</td>\n",
              "      <td>59,130</td>\n",
              "      <td>AL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    County Population State\n",
              "0  Autauga     58,800    AL\n",
              "1  Baldwin    231,767    AL\n",
              "2  Barbour     25,226    AL\n",
              "3     Bibb     22,284    AL\n",
              "4   Blount     59,130    AL"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop the original full state name column\n",
        "df_county_pop = df_county_pop.drop(columns=['State'])\n",
        "\n",
        "# Rename the abbreviation column\n",
        "df_county_pop = df_county_pop.rename(columns={'State_Abbrev': 'State'})\n",
        "df_county_pop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, I will create \"County_norm\" and \"State_norm\" to match counties in both DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_county(name):\n",
        "    name = name.lower().strip()\n",
        "    \n",
        "    # Remove parenthetical content, e.g., \" (city)\"\n",
        "    name = re.sub(r\"\\s*\\(.*?\\)\\s*\", \"\", name)\n",
        "    \n",
        "    # Replace common suffixes\n",
        "    remove_terms = [\n",
        "        \" county\", \" parish\", \" borough\", \" census area\", \n",
        "        \" independent city\", \" municipality\", \" district\",\n",
        "        \" planning region\", \" region\"\n",
        "    ]\n",
        "    for term in remove_terms:\n",
        "        name = name.replace(term, \"\")\n",
        "    \n",
        "    # Normalize \"st.\" or \"st\" to \"st\"\n",
        "    name = re.sub(r\"\\bst\\.?\", \"st\", name)\n",
        "    \n",
        "    # Remove extra spaces\n",
        "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
        "    \n",
        "    return name\n",
        "\n",
        "# Apply to dataset\n",
        "df['County_norm'] = df['County'].apply(normalize_county)\n",
        "\n",
        "df_county_pop['County_norm'] = df_county_pop['County'].apply(normalize_county)\n",
        "df_county_pop['State_norm'] = df_county_pop['State'].str.lower().str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counties in df found in df_county_pop: 953\n",
            "Counties in df NOT found in df_county_pop: 24\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('suffolk', 'va'),\n",
              " ('fredericksburg', 'va'),\n",
              " ('charlottesville', 'va'),\n",
              " ('winchester', 'va'),\n",
              " ('de kalb', 'tn'),\n",
              " ('macon-bibb', 'ga'),\n",
              " ('bristol', 'va'),\n",
              " ('harrisonburg', 'va'),\n",
              " ('fairfield', 'ct'),\n",
              " ('virginia beach', 'va'),\n",
              " ('chesapeake', 'va'),\n",
              " ('new london', 'ct'),\n",
              " ('alexandria', 'va'),\n",
              " ('norfolk', 'va'),\n",
              " ('queen annes', 'md'),\n",
              " ('colonial heights', 'va'),\n",
              " ('middlesex', 'ct'),\n",
              " ('prince georges', 'md'),\n",
              " ('hartford', 'ct'),\n",
              " ('newport news', 'va')]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make sets of counties (and states) in each dataset\n",
        "acc_counties = set(zip(df['County_norm'], df['State_norm']))\n",
        "pop_counties = set(zip(df_county_pop['County_norm'], df_county_pop['State_norm']))\n",
        "\n",
        "# Count how many cities in df_balanced are in df_pop\n",
        "matched = acc_counties & pop_counties\n",
        "print(f\"Counties in df found in df_county_pop: {len(matched)}\")\n",
        "print(f\"Counties in df NOT found in df_county_pop: {len(acc_counties - pop_counties)}\")\n",
        "\n",
        "# show first 20 unmatched pairs to inspect\n",
        "list(acc_counties - pop_counties)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before merging the DataFrames, I am checking for duplicates that may have arisen due to the actions of normalisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicate city-state pairs in df_pop: 49\n",
            "      Population                   City State              City_norm  \\\n",
            "3269       4,714        Beecher village    IL        beecher village   \n",
            "3270         429       Beecher  village    IL        beecher village   \n",
            "14706        177    Centerville borough    PA    centerville borough   \n",
            "14707      3,257    Centerville borough    PA    centerville borough   \n",
            "16718      2,853            Clarksville    TX            clarksville   \n",
            "16719        768            Clarksville    TX            clarksville   \n",
            "6686       1,030                   Clay    KY                   clay   \n",
            "6687       1,194                   Clay    KY                   clay   \n",
            "14740        129       Coaldale borough    PA       coaldale borough   \n",
            "14741      2,427       Coaldale borough    PA       coaldale borough   \n",
            "18976        234          Genoa village    WI          genoa village   \n",
            "18977      2,982         Genoa  village    WI          genoa village   \n",
            "14994        253      Jefferson borough    PA      jefferson borough   \n",
            "14995        653      Jefferson borough    PA      jefferson borough   \n",
            "3771          57       Junction village    IL       junction village   \n",
            "3772         532      Junction  village    IL       junction village   \n",
            "17110        338          Lakeside town    TX          lakeside town   \n",
            "17111      1,648          Lakeside town    TX          lakeside town   \n",
            "17112      1,076         Lakeside  town    TX          lakeside town   \n",
            "15050      2,357        Liberty borough    PA        liberty borough   \n",
            "15051        231        Liberty borough    PA        liberty borough   \n",
            "4806         883            Monroe town    IN            monroe town   \n",
            "4807         493           Monroe  town    IN            monroe town   \n",
            "15182         83        Newburg borough    PA        newburg borough   \n",
            "15183        350        Newburg borough    PA        newburg borough   \n",
            "4028         174         Norris village    IL         norris village   \n",
            "4029       1,142        Norris  village    IL         norris village   \n",
            "17303        238         Oak Ridge town    TX         oak ridge town   \n",
            "17304        781         Oak Ridge town    TX         oak ridge town   \n",
            "13427      3,573        Oakwood village    OH        oakwood village   \n",
            "13429        548        Oakwood village    OH        oakwood village   \n",
            "6440         115                   Park    KS                   park   \n",
            "6441       8,354                   Park    KS                   park   \n",
            "4105         107          Pearl village    IL          pearl village   \n",
            "4106         782         Pearl  village    IL          pearl village   \n",
            "15277        196  Pleasantville borough    PA  pleasantville borough   \n",
            "15278        848  Pleasantville borough    PA  pleasantville borough   \n",
            "17424      3,459                   Reno    TX                   reno   \n",
            "17425      2,861                   Reno    TX                   reno   \n",
            "5782       1,072               Rockwell    IA               rockwell   \n",
            "5783       2,261               Rockwell    IA               rockwell   \n",
            "8789       9,264            St. Anthony    MN            st. anthony   \n",
            "8790          92            St. Anthony    MN            st. anthony   \n",
            "4300         227       Standard village    IL       standard village   \n",
            "4301         132      Standard  village    IL       standard village   \n",
            "4421       2,282          Wayne village    IL          wayne village   \n",
            "4422       1,007         Wayne  village    IL          wayne village   \n",
            "5943          95                Webster    IA                webster   \n",
            "5944       7,827                Webster    IA                webster   \n",
            "\n",
            "      State_norm  \n",
            "3269          il  \n",
            "3270          il  \n",
            "14706         pa  \n",
            "14707         pa  \n",
            "16718         tx  \n",
            "16719         tx  \n",
            "6686          ky  \n",
            "6687          ky  \n",
            "14740         pa  \n",
            "14741         pa  \n",
            "18976         wi  \n",
            "18977         wi  \n",
            "14994         pa  \n",
            "14995         pa  \n",
            "3771          il  \n",
            "3772          il  \n",
            "17110         tx  \n",
            "17111         tx  \n",
            "17112         tx  \n",
            "15050         pa  \n",
            "15051         pa  \n",
            "4806          in  \n",
            "4807          in  \n",
            "15182         pa  \n",
            "15183         pa  \n",
            "4028          il  \n",
            "4029          il  \n",
            "17303         tx  \n",
            "17304         tx  \n",
            "13427         oh  \n",
            "13429         oh  \n",
            "6440          ks  \n",
            "6441          ks  \n",
            "4105          il  \n",
            "4106          il  \n",
            "15277         pa  \n",
            "15278         pa  \n",
            "17424         tx  \n",
            "17425         tx  \n",
            "5782          ia  \n",
            "5783          ia  \n",
            "8789          mn  \n",
            "8790          mn  \n",
            "4300          il  \n",
            "4301          il  \n",
            "4421          il  \n",
            "4422          il  \n",
            "5943          ia  \n",
            "5944          ia  \n",
            "Duplicate county-state pairs in df_cpop: 0\n",
            "Empty DataFrame\n",
            "Columns: [County, Population, State, County_norm, State_norm]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# Check df_pop for duplicate city-state pairs\n",
        "dupes_city_pop = df_city_pop[df_city_pop.duplicated(subset=['City_norm', 'State_norm'], keep=False)]\n",
        "print(f\"Duplicate city-state pairs in df_pop: {dupes_city_pop.value_counts().sum()}\")\n",
        "print(dupes_city_pop.sort_values(['City_norm', 'State_norm']))\n",
        "\n",
        "# Check df_cpop for duplicate county-state pairs\n",
        "dupes_county_pop = df_county_pop[df_county_pop.duplicated(subset=['County_norm', 'State_norm'], keep=False)]\n",
        "print(f\"Duplicate county-state pairs in df_cpop: {dupes_county_pop.value_counts().sum()}\")\n",
        "print(dupes_county_pop.sort_values(['County_norm', 'State_norm']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I can see that there are 49 City-State pair duplicates but 0 Couty-State pair duplicates. I am going to delete the City-State duplicates to prevent errors when merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_city_pop_clean = df_city_pop[~df_city_pop.index.isin(dupes_city_pop.index)].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, I will merge on \"City_norm\" and \"State_norm\" to get \"Population_city\". I'm checking the shape after merging to ensure that duplications aren't occurring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 42)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge city population\n",
        "df = df.merge(df_city_pop_clean[['City_norm','State_norm','Population']],\n",
        "                                left_on=['City_norm','State_norm'],\n",
        "                                right_on=['City_norm','State_norm'],\n",
        "                                how='left')\n",
        "df.rename(columns={'Population':'Population_city'}, inplace=True)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, I'm merging on \"County_norm\" and \"State_norm\", and again checking the shape after merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 43)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge county population\n",
        "df = df.merge(df_county_pop[['County_norm','State_norm','Population']],\n",
        "                                left_on=['County_norm','State_norm'],\n",
        "                                right_on=['County_norm','State_norm'],\n",
        "                                how='left')\n",
        "df.rename(columns={'Population':'Population_county'}, inplace=True)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, I'm creating the \"Population\" column that I will keep, which takes \"Population_city\" if available, otherwise it fills with \"Population_county\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 44)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fill final population using city first, then County\n",
        "df['Population'] = df['Population_city'].fillna(df['Population_county'])\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that in the end, there are 40 instances without a value for \"Population\", which I will drop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2597\n",
            "125\n",
            "40\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Population_city\"].isna().sum())\n",
        "print(df[\"Population_county\"].isna().sum())\n",
        "print(df[\"Population\"].isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9960, 44)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna(subset=['Population'])\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, I will need to strip the comma from the values of \"Population\" and change the data type from object to integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Population\"].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('int32')"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Population\"] = df[\"Population\"].str.replace(\",\", \"\", regex=False).astype(int)\n",
        "df[\"Population\"].dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, I will look at the boolean variables and see if any should be dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amenity: 2\n",
            "[False  True]\n",
            "Bump: 2\n",
            "[False  True]\n",
            "Crossing: 2\n",
            "[False  True]\n",
            "Give_Way: 2\n",
            "[False  True]\n",
            "Junction: 2\n",
            "[False  True]\n",
            "No_Exit: 2\n",
            "[False  True]\n",
            "Railway: 2\n",
            "[False  True]\n",
            "Roundabout: 1\n",
            "[False]\n",
            "Station: 2\n",
            "[False  True]\n",
            "Stop: 2\n",
            "[False  True]\n",
            "Traffic_Calming: 2\n",
            "[False  True]\n",
            "Traffic_Signal: 2\n",
            "[False  True]\n",
            "Turning_Loop: 1\n",
            "[False]\n"
          ]
        }
      ],
      "source": [
        "for col in df.select_dtypes(include=\"boolean\").columns:\n",
        "    print(f\"{col}: {df[col].nunique()}\")\n",
        "    print(f\"{df[col].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "## Conclusion and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
